{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = 'train'\n",
    "test_file_path = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load/resize the image from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size =(180, 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 557 files belonging to 2 classes.\n",
      "Using 446 files for training.\n"
     ]
    }
   ],
   "source": [
    "data_train = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_file_path,\n",
    "    shuffle= True,\n",
    "    image_size= image_size,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    seed=123,\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 557 files belonging to 2 classes.\n",
      "Using 111 files for validation.\n"
     ]
    }
   ],
   "source": [
    "data_val = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_file_path,\n",
    "    shuffle= True,\n",
    "    image_size= image_size,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    seed=123,\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 140 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data_test = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_file_path,\n",
    "    shuffle= False,\n",
    "    image_size= image_size,\n",
    "    batch_size=32,\n",
    "    validation_split=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the image classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cats', 'dogs']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cat = data_train.class_names\n",
    "data_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply rescaling to normalize pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.map(lambda x, y: (x / 255.0, y))\n",
    "data_val = data_val.map(lambda x, y: (x / 255.0, y))\n",
    "data_test = data_test.map(lambda x, y: (x / 255.0, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the image classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train_list = list(data_train)\n",
    "# img = random.randint(0, len(data_train_list) - 1)\n",
    "# sample = data_train_list[img]  \n",
    "\n",
    "# if len(sample[0].shape) == 4:  \n",
    "#     single_image = sample[0][0] \n",
    "# else:\n",
    "#     single_image = sample[0]\n",
    "\n",
    "# plt.imshow(single_image)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the model using functional api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the input layer with the shape of the input images\n",
    "input_shape = (180, 180, 3)  \n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Add convolutional and pooling layers\n",
    "x = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "# Flatten the output of the convolutional layers\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Define the fully connected layers\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Add the output layer\n",
    "output_layer = Dense(1, activation='sigmoid')(x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 180, 180, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 178, 178, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 89, 89, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 87, 87, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 43, 43, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 41, 41, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 20, 20, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 51200)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               6553728   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,647,105\n",
      "Trainable params: 6,647,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "14/14 [==============================] - 15s 894ms/step - loss: 0.9647 - accuracy: 0.4955 - val_loss: 0.7010 - val_accuracy: 0.4865\n",
      "Epoch 2/15\n",
      "14/14 [==============================] - 13s 866ms/step - loss: 0.6962 - accuracy: 0.4821 - val_loss: 0.6924 - val_accuracy: 0.4865\n",
      "Epoch 3/15\n",
      "14/14 [==============================] - 13s 887ms/step - loss: 0.6918 - accuracy: 0.5493 - val_loss: 0.6927 - val_accuracy: 0.4865\n",
      "Epoch 4/15\n",
      "14/14 [==============================] - 14s 932ms/step - loss: 0.6850 - accuracy: 0.5717 - val_loss: 0.6855 - val_accuracy: 0.5856\n",
      "Epoch 5/15\n",
      "14/14 [==============================] - 14s 947ms/step - loss: 0.6749 - accuracy: 0.6031 - val_loss: 0.6836 - val_accuracy: 0.5495\n",
      "Epoch 6/15\n",
      "14/14 [==============================] - 15s 977ms/step - loss: 0.6408 - accuracy: 0.6704 - val_loss: 0.6839 - val_accuracy: 0.5225\n",
      "Epoch 7/15\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.5692 - accuracy: 0.7354 - val_loss: 0.7034 - val_accuracy: 0.5766\n",
      "Epoch 8/15\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.4776 - accuracy: 0.7780 - val_loss: 0.7430 - val_accuracy: 0.5676\n",
      "Epoch 9/15\n",
      "14/14 [==============================] - 18s 1s/step - loss: 0.3581 - accuracy: 0.8318 - val_loss: 0.8075 - val_accuracy: 0.6757\n",
      "Epoch 10/15\n",
      "14/14 [==============================] - 21s 1s/step - loss: 0.2749 - accuracy: 0.8879 - val_loss: 1.0185 - val_accuracy: 0.5946\n",
      "Epoch 11/15\n",
      "14/14 [==============================] - 24s 2s/step - loss: 0.2013 - accuracy: 0.9215 - val_loss: 1.2359 - val_accuracy: 0.6216\n",
      "Epoch 12/15\n",
      "14/14 [==============================] - 29s 2s/step - loss: 0.1907 - accuracy: 0.9439 - val_loss: 1.2717 - val_accuracy: 0.6036\n",
      "Epoch 13/15\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.1404 - accuracy: 0.9619 - val_loss: 1.7041 - val_accuracy: 0.6577\n",
      "Epoch 14/15\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.0879 - accuracy: 0.9753 - val_loss: 1.7138 - val_accuracy: 0.6667\n",
      "Epoch 15/15\n",
      "14/14 [==============================] - 29s 2s/step - loss: 0.0628 - accuracy: 0.9843 - val_loss: 1.9920 - val_accuracy: 0.6486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f04ba25940>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data_train, validation_data=data_val, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.6779324e-16]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Create an iterator\n",
    "data_iter = iter(data_test)\n",
    "\n",
    "# Get a random batch by iterating through the dataset\n",
    "idx2 = random.randint(0, len(data_test) - 1)\n",
    "for i in range(idx2 + 1):\n",
    "    batch = next(data_iter)\n",
    "\n",
    "# Select a random image from the batch\n",
    "batch_size = batch[0].shape[0]\n",
    "img_in_batch = random.randint(0, batch_size - 1)\n",
    "single_image = batch[0][img_in_batch]\n",
    "\n",
    "# Convert to numpy \n",
    "if isinstance(single_image, tf.Tensor):\n",
    "    single_image = single_image.numpy()\n",
    "\n",
    "\n",
    "\n",
    "# preprocess the image\n",
    "image = Image.fromarray((single_image * 255).astype(np.uint8))  \n",
    "image = tf.keras.utils.img_to_array(image)\n",
    "image = tf.image.resize(image, (180, 180))  \n",
    "\n",
    "# Expand dimensions to create a batch of one image\n",
    "image_batch = tf.expand_dims(image, 0)\n",
    "\n",
    "# Predict using the model\n",
    "predict = model.predict(image_batch)\n",
    "predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The animal in image is cats with accuracy of 50.00\n"
     ]
    }
   ],
   "source": [
    "score = tf.nn.sigmoid(predict)\n",
    "print(\"The animal in image is {} with accuracy of {:0.2f}\".format(data_cat[np.argmax(score)], np.max(score)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: animal prediction\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: animal prediction\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('animal prediction')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
